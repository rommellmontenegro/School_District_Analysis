{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9aeaf3e8-850d-4cff-b3ee-ffb6a20c236c",
   "metadata": {},
   "source": [
    "# ***Google Drive Bootup***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d89a9adb-59cc-4416-bd10-17ddf904652f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import pandas as pd\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "from httplib2 import Http\n",
    "from httplib2 import Http\n",
    "from apiclient.http import MediaFileUpload,MediaIoBaseDownload\n",
    "import io\n",
    "\n",
    "# If modifying these scopes, delete the file token.json.\n",
    "SCOPES = ['https://www.googleapis.com/auth/drive']\n",
    "\n",
    "creds = None\n",
    "  # The file token.json stores the user's access and refresh tokens, and is\n",
    "  # created automatically when the authorization flow completes for the first\n",
    "  # time.\n",
    "if os.path.exists(\"token.json\"):\n",
    "    creds = Credentials.from_authorized_user_file(\"token.json\", SCOPES)\n",
    "  # If there are no (valid) credentials available, let the user log in.\n",
    "if not creds or not creds.valid:\n",
    "    if creds and creds.expired and creds.refresh_token:\n",
    "      creds.refresh(Request())\n",
    "    else:\n",
    "      flow = InstalledAppFlow.from_client_secrets_file(\n",
    "          \"client_secret_833249459653-01pcjla0c9re30fgr2dfipcgg5lgq6j0.apps.googleusercontent.com.json\", SCOPES\n",
    "      )\n",
    "      creds = flow.run_local_server(port=0)\n",
    "    # Save the credentials for the next run\n",
    "    with open(\"token.json\", \"w\") as token:\n",
    "      token.write(creds.to_json())\n",
    "    \n",
    "# Call the Drive v3 API\n",
    "drive = build(\"drive\", \"v3\", credentials=creds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5aef6a7-6335-4253-a325-b8765c23be37",
   "metadata": {},
   "source": [
    "# ***Google Folders Reporting***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55daeacb-079c-4b27-b96c-d1ea1175e625",
   "metadata": {},
   "source": [
    "### ***Import CSV File for Multiple Folder Processing***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a72fbcc6-6206-4169-99b3-bfd4832b780f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File Index</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>webViewLink</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>650</td>\n",
       "      <td>1CXbxo5lFw_9La_uX81DT7TK-O7jOpCC7</td>\n",
       "      <td>IP Theft Claim</td>\n",
       "      <td>https://drive.google.com/drive/folders/1CXbxo5...</td>\n",
       "      <td>LEGAL/Legal Case/Reports/Claims</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>651</td>\n",
       "      <td>1ioa4eJyv5IiaDtxhbn6VGjoS30HGhyYg</td>\n",
       "      <td>Non-Profits</td>\n",
       "      <td>https://drive.google.com/drive/folders/1ioa4eJ...</td>\n",
       "      <td>LEGAL/Legal Case/Emails &amp; Texts/Relevant Incid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>652</td>\n",
       "      <td>1rEX-AMTBx7EYdHnntTHWX8Ra9mfY40NE</td>\n",
       "      <td>CA HUD</td>\n",
       "      <td>https://drive.google.com/drive/folders/1rEX-AM...</td>\n",
       "      <td>LEGAL/Legal Case/Emails &amp; Texts/Relevant Incid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>653</td>\n",
       "      <td>15G7_fBtLtXq6paBl8jfoofkeh4CPPsbq</td>\n",
       "      <td>CA Civil Rights Department</td>\n",
       "      <td>https://drive.google.com/drive/folders/15G7_fB...</td>\n",
       "      <td>LEGAL/Legal Case/Emails &amp; Texts/Relevant Incid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>654</td>\n",
       "      <td>1Cm4AoGbabhpoitAxaRALv9IETTQMaIWs</td>\n",
       "      <td>Manager Liability</td>\n",
       "      <td>https://drive.google.com/drive/folders/1Cm4AoG...</td>\n",
       "      <td>LEGAL/Legal Case/Reports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>802</td>\n",
       "      <td>13cj-NWqB2z4bSTD-6oim2G_WsBwcRkHX</td>\n",
       "      <td>Joe Fierro - House Manager</td>\n",
       "      <td>https://drive.google.com/drive/folders/13cj-NW...</td>\n",
       "      <td>LEGAL/Legal Case/Emails &amp; Texts/Relevant Incid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>803</td>\n",
       "      <td>1Krennb-CdBWsEDpVm6BpL6nhqt6_mPFx</td>\n",
       "      <td>Storm Weiner - Network Manager &amp; Mail Manager</td>\n",
       "      <td>https://drive.google.com/drive/folders/1Krennb...</td>\n",
       "      <td>LEGAL/Legal Case/Emails &amp; Texts/Relevant Incid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>804</td>\n",
       "      <td>17r4nOfkVEPA3WuwVVWT5q_p9s1CVkQz5</td>\n",
       "      <td>Mobile Graphic &amp; Video Media</td>\n",
       "      <td>https://drive.google.com/drive/folders/17r4nOf...</td>\n",
       "      <td>LEGAL/Legal Case</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>805</td>\n",
       "      <td>1zY8znayaEy7u2J8XPJQtlfHI59b9jjd0</td>\n",
       "      <td>Records</td>\n",
       "      <td>https://drive.google.com/drive/folders/1zY8zna...</td>\n",
       "      <td>LEGAL/Legal Case</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>806</td>\n",
       "      <td>1W45HJkOgPLo5QaHS2hSHkiIkL5RyopVj</td>\n",
       "      <td>Legal Case</td>\n",
       "      <td>https://drive.google.com/drive/folders/1W45HJk...</td>\n",
       "      <td>LEGAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>154 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     File Index                                 id  \\\n",
       "0           650  1CXbxo5lFw_9La_uX81DT7TK-O7jOpCC7   \n",
       "1           651  1ioa4eJyv5IiaDtxhbn6VGjoS30HGhyYg   \n",
       "2           652  1rEX-AMTBx7EYdHnntTHWX8Ra9mfY40NE   \n",
       "3           653  15G7_fBtLtXq6paBl8jfoofkeh4CPPsbq   \n",
       "4           654  1Cm4AoGbabhpoitAxaRALv9IETTQMaIWs   \n",
       "..          ...                                ...   \n",
       "149         802  13cj-NWqB2z4bSTD-6oim2G_WsBwcRkHX   \n",
       "150         803  1Krennb-CdBWsEDpVm6BpL6nhqt6_mPFx   \n",
       "151         804  17r4nOfkVEPA3WuwVVWT5q_p9s1CVkQz5   \n",
       "152         805  1zY8znayaEy7u2J8XPJQtlfHI59b9jjd0   \n",
       "153         806  1W45HJkOgPLo5QaHS2hSHkiIkL5RyopVj   \n",
       "\n",
       "                                              name  \\\n",
       "0                                   IP Theft Claim   \n",
       "1                                      Non-Profits   \n",
       "2                                           CA HUD   \n",
       "3                       CA Civil Rights Department   \n",
       "4                                Manager Liability   \n",
       "..                                             ...   \n",
       "149                     Joe Fierro - House Manager   \n",
       "150  Storm Weiner - Network Manager & Mail Manager   \n",
       "151                   Mobile Graphic & Video Media   \n",
       "152                                        Records   \n",
       "153                                     Legal Case   \n",
       "\n",
       "                                           webViewLink  \\\n",
       "0    https://drive.google.com/drive/folders/1CXbxo5...   \n",
       "1    https://drive.google.com/drive/folders/1ioa4eJ...   \n",
       "2    https://drive.google.com/drive/folders/1rEX-AM...   \n",
       "3    https://drive.google.com/drive/folders/15G7_fB...   \n",
       "4    https://drive.google.com/drive/folders/1Cm4AoG...   \n",
       "..                                                 ...   \n",
       "149  https://drive.google.com/drive/folders/13cj-NW...   \n",
       "150  https://drive.google.com/drive/folders/1Krennb...   \n",
       "151  https://drive.google.com/drive/folders/17r4nOf...   \n",
       "152  https://drive.google.com/drive/folders/1zY8zna...   \n",
       "153  https://drive.google.com/drive/folders/1W45HJk...   \n",
       "\n",
       "                                                  path  \n",
       "0                      LEGAL/Legal Case/Reports/Claims  \n",
       "1    LEGAL/Legal Case/Emails & Texts/Relevant Incid...  \n",
       "2    LEGAL/Legal Case/Emails & Texts/Relevant Incid...  \n",
       "3    LEGAL/Legal Case/Emails & Texts/Relevant Incid...  \n",
       "4                             LEGAL/Legal Case/Reports  \n",
       "..                                                 ...  \n",
       "149  LEGAL/Legal Case/Emails & Texts/Relevant Incid...  \n",
       "150  LEGAL/Legal Case/Emails & Texts/Relevant Incid...  \n",
       "151                                   LEGAL/Legal Case  \n",
       "152                                   LEGAL/Legal Case  \n",
       "153                                              LEGAL  \n",
       "\n",
       "[154 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#GoogleErrorFiles = '/Users/rommellmontenegro/Desktop/Civil Suit*/5 - Mobile Graphic & Video Media/RICO Album Tables/ADMIN-Working Files/Error Files/'\n",
    "#errordf = pd.read_excel(GoogleErrorFiles + '2025.01.10_21.16_REVIEWED Errors_from_GDrive_Folders Rework.xlsx', sheet_name=\"Working\")\n",
    "#errordf = errordf.sort_values(by='name')\n",
    "#if 'Unnamed: 0' in errordf.columns:\n",
    "#    errordf.rename(columns={'Unnamed: 0': 'File Index'}, inplace=True)\n",
    "#errordf\n",
    "PC = 14\n",
    "filename = '2025.05.07_20.35 GDrive_LEGAL_Folders 1.xlsx'\n",
    "\n",
    "GoogleFolderFiles = '/Users/rommellmontenegro/Desktop/Civil Suit*/5 - Mobile Graphic & Video Media/RICO Album Tables/ADMIN-Working Files/GDrive Folder Lists/'\n",
    "folderdf = pd.read_excel(GoogleFolderFiles + filename)\n",
    "folderdf = folderdf.sort_values(by='name')\n",
    "if 'Unnamed: 0' in folderdf.columns:\n",
    "    folderdf.rename(columns={'Unnamed: 0': 'File Index'}, inplace=True)\n",
    "folderdf = folderdf.sort_values(by='File Index')\n",
    "folderdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbce77b-e1fb-4280-8fa1-fa2963dbac68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DriveFoldersDEBUG(FolderName,Path):\n",
    "    query = \"mimeType = 'application/vnd.google-apps.folder' and name = \" + FolderName\n",
    "\n",
    "    from time import mktime\n",
    "    import datetime\n",
    "    from datetime import datetime\n",
    "    import os.path\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    from google.auth.transport.requests import Request\n",
    "    from google.oauth2.credentials import Credentials\n",
    "    from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "    from googleapiclient.discovery import build\n",
    "    from googleapiclient.errors import HttpError\n",
    "    import os\n",
    "    import subprocess\n",
    "    import time\n",
    "    global dffilecount, filename, foldersize, folderid, FolderName2, Locked, File_Type\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "    \n",
    "    currentDateTime = datetime.now()\n",
    "    date = currentDateTime.date()\n",
    "    year = date.strftime(\"%Y\") #except: 2022\n",
    "    date.strftime(\"%Y\")\n",
    "\n",
    "    d = datetime.now()\n",
    "    only_date, only_time = d.date(), d.time()\n",
    "    only_date = only_date.strftime('%Y.%m.%d')\n",
    "    only_time = only_time.strftime('%H.%M')\n",
    "    procTS = str(only_date) + \"_\" + str(only_time)\n",
    "    dffilecount = 0\n",
    "    FolderName2 = FolderName.replace(\"'\", \"\")\n",
    "    \n",
    "    if PC == 13:\n",
    "        Base = \"/Volumes/My Passport for Mac/Evidence/5 - Mobile Graphic & Video Media/\"\n",
    "        Local = \"/Users/rommell/Desktop/L - Civil Suit/RICO Album Tables/\"\n",
    "        External = \"/Volumes/My Passport for Mac/Evidence/5 - Media Documentation/\"\n",
    "\n",
    "    if PC == 14:\n",
    "        Base = \"/Volumes/Files/2022 MacBook Pro/LARGE FOLDERS/Civil Suit & Evidence/Civil Suit*/5 - Mobile Graphic & Video Media/11.17.24 RICO at Hip/\"\n",
    "        Local = \"/Users/rommellmontenegro/Desktop/Civil Suit*/5 - Mobile Graphic & Video Media/RICO Album Tables/Combine/Google Files/\"\n",
    "        External = \"/Volumes/Files/2022 MacBook Pro/LARGE FOLDERS/Civil Suit & Evidence/Civil Suit*/5 - Mobile Graphic & Video Media/FILES TABLES/\"\n",
    "\n",
    "    # If modifying these scopes, delete the file token.json.\n",
    "    SCOPES = ['https://www.googleapis.com/auth/spreadsheets', 'https://www.googleapis.com/auth/drive']\n",
    "\n",
    "    files = []\n",
    "\n",
    "    creds = None\n",
    "      # The file token.json stores the user's access and refresh tokens, and is\n",
    "      # created automatically when the authorization flow completes for the first\n",
    "      # time.\n",
    "    if os.path.exists(\"token.json\"):\n",
    "        creds = Credentials.from_authorized_user_file(\"token.json\", SCOPES)\n",
    "      # If there are no (valid) credentials available, let the user log in.\n",
    "    if not creds or not creds.valid:\n",
    "        if creds and creds.expired and creds.refresh_token:\n",
    "          creds.refresh(Request())\n",
    "        else:\n",
    "          flow = InstalledAppFlow.from_client_secrets_file(\n",
    "              \"client_secret_833249459653-01pcjla0c9re30fgr2dfipcgg5lgq6j0.apps.googleusercontent.com.json\", SCOPES\n",
    "          )\n",
    "          creds = flow.run_local_server(port=0)\n",
    "        # Save the credentials for the next run\n",
    "        with open(\"token.json\", \"w\") as token:\n",
    "          token.write(creds.to_json())\n",
    "\n",
    "    # Call the Drive v3 API\n",
    "    drive = build(\"drive\", \"v3\", credentials=creds)\n",
    "\n",
    "    # First, get the folder ID by querying by mimeType and name\n",
    "    folderId = drive.files().list(q = query, pageSize=1000, fields=\"nextPageToken,files(id, name,webViewLink,size,contentRestrictions)\").execute()\n",
    "\n",
    "    # this gives us a list of all folders with that name\n",
    "    folderIdResult = folderId.get('files', [])\n",
    "    # however, we know there is only 1 folder with that name, so we just get the id of the 1st item in the list\n",
    "    id = folderIdResult[0].get('id')\n",
    "    folderid = pd.Series(id)\n",
    "    \n",
    "    # Now, using the folder ID gotten above, we get all the files from that particular folder in a dictionary file of the resulting file id, name, and weblink FOR ONLY the first 1000 results.\n",
    "    results = drive.files().list(q = \"'\" + id + \"' in parents\", pageSize=1000, fields=\"nextPageToken, files(id, name,webViewLink,size,contentRestrictions)\").execute()\n",
    "\n",
    "    #Creates in a smaller dictionary file with only the data of file id, name, and weblink which can be made into a dataframe object.\n",
    "    items = results.get('files', [])\n",
    "    \n",
    "    page_token = None\n",
    "    while True:\n",
    "    # Now, using the folder ID gotten above, we get all the files from that particular folder in a dictionary file of the resulting file id, name, and weblink results.\n",
    "      response = (\n",
    "          drive.files()\n",
    "          .list(\n",
    "              q= \"'\" + id + \"' in parents\",\n",
    "              #q=\"mimeType = 'application/vnd.google-apps.folder'\",\n",
    "              spaces=\"drive\",\n",
    "              fields=\"nextPageToken, files(id, name, webViewLink, size, contentRestrictions)\",\n",
    "              pageToken=page_token,\n",
    "          )\n",
    "          .execute()\n",
    "      )\n",
    "        \n",
    "#       response = drive.files().get(fileId=\"FILE_ID\", fields = \"contentRestrictions\").execute(); \n",
    "        \n",
    "    #Creates in a smaller dictionary file with only the data of file id, name, and weblink which can be made into a dataframe object.\n",
    "      for file in response.get(\"files\", []):\n",
    "        items.append(file)\n",
    "      files.extend(response.get(\"files\", []))\n",
    "    \n",
    "      page_token = response.get(\"nextPageToken\", None)\n",
    "      if page_token is None:\n",
    "        break\n",
    "        \n",
    "    #Creates the dataframe of the results\n",
    "    df = pd.DataFrame(items, columns=['id', 'name', 'webViewLink', 'contentRestrictions', 'size','urlparts','ObjectType','readOnly'])\n",
    "    df = df[df['name'] != '.DS_Store']\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df.fillna(0, inplace=True)\n",
    "    if 'size' not in df.columns:\n",
    "        df['size'] = 0\n",
    "    if 'urlparts' not in df.columns:\n",
    "        df['urlparts'] = np.nan\n",
    "        df['urlparts'] = df['urlparts'].astype(str)\n",
    "    df['size'] = df['size'].astype(int)\n",
    "    foldersum = df['size'].sum()\n",
    "    if 'ObjectType' not in df.columns:    \n",
    "        df['ObjectType'] = ''\n",
    "    if 'readOnly' not in df.columns:    \n",
    "        df['readOnly'] = ''\n",
    "\n",
    "    df['ObjectType'] = df.ObjectType.astype(str)\n",
    "    df['urlparts'] = df['webViewLink'].str.split(\"/\")\n",
    "    df['urlparts'] = df.urlparts.astype(str)\n",
    "    df['urlparts'] = df['urlparts']\n",
    "    df['urlparts'] = df['urlparts'].tolist()\n",
    "    df['urlparts4'] = df['urlparts'].apply(lambda x: x[45:52]).astype(str)\n",
    "    df['urlparts4'] = df.urlparts4.astype(str)\n",
    "    df['urlparts3'] = df['urlparts'].apply(lambda x: x[36:40])\n",
    "    df['urlparts3'] = df['urlparts3'].astype(str)    \n",
    "    df['ObjectType'] = df['ObjectType'].astype(str)\n",
    "\n",
    "    conditions1 = [\n",
    "    df['urlparts4'] == 'folders',\n",
    "    df['urlparts3'] == 'file',\n",
    "    df['urlparts3'] == 'prea']\n",
    "    choices1 = ['Folder', 'File', 'File']\n",
    "    df['ObjectType'] = np.select(conditions1, choices1, default='')\n",
    "\n",
    "    if 'contentRestrictions' in df.columns:\n",
    "        for index, row in df.iterrows():\n",
    "            if row['ObjectType'] == 'File':\n",
    "                try: df['readOnly'] = df['contentRestrictions'][0][0].get(\"readOnly\")\n",
    "                except IndexError:\n",
    "                     if pd.isna(row['readOnly'])==True:\n",
    "                        df['readOnly'] = 'Unlocked'  \n",
    "                except KeyError:\n",
    "                    if pd.isna(row['readOnly'])==True:\n",
    "                        df['readOnly'] = 'Unlocked'\n",
    "                except TypeError: \n",
    "                    if pd.isna(row['readOnly'])==True:\n",
    "                        df['readOnly'] = 'Unlocked'\n",
    "                except HttpError:\n",
    "                    if pd.isna(row['readOnly'])==True:\n",
    "                        df['readOnly'] = 'Unlocked'\n",
    "                        \n",
    "    df['contentRestrictions'].replace(['0', '0.0'], 'Unlocked', inplace=True)\n",
    "    df['contentRestrictions'] = df['contentRestrictions'].astype(str)\n",
    "    df['readOnly'] = df['contentRestrictions'].apply(lambda x: x[:1]).astype(str)\n",
    "\n",
    "    dfFolder = pd.DataFrame(columns=['id', 'name', 'webViewLink', 'contentRestrictions', 'size','urlparts','ObjectType','readOnly'])\n",
    "    for index, row in df.iterrows():\n",
    "        if row['ObjectType'] == 'Folder':\n",
    "            dfFolder = df[df[\"ObjectType\"] == 'Folder']\n",
    "            dfFolder['readOnly'].replace(['0', '0.0'], 'Folder', inplace=True)\n",
    "\n",
    "    dfLockedFile = pd.DataFrame(columns=['id', 'name', 'webViewLink', 'contentRestrictions', 'size','urlparts','ObjectType','readOnly'])\n",
    "    for index, row in df.iterrows():\n",
    "        if row['ObjectType'] == 'File' and row['readOnly'] == '[':\n",
    "            dfLockedFile = df[df['readOnly'] == '[']\n",
    "            dfLockedFile['readOnly'].replace('[', 'Locked', inplace=True)\n",
    "    \n",
    "    dfUnLockedFile2 = pd.DataFrame(columns=['id', 'name', 'webViewLink', 'contentRestrictions', 'size','urlparts','ObjectType','readOnly'])    \n",
    "    for index, row in df.iterrows():\n",
    "        if row['ObjectType'] == 'File' and row['readOnly'] == '0':\n",
    "            dfUnLockedFile = df\n",
    "            dfUnLockedFile1 = dfUnLockedFile[dfUnLockedFile['readOnly'] == '0']\n",
    "            dfUnLockedFile2 = dfUnLockedFile1[dfUnLockedFile1['ObjectType'] == 'File']            \n",
    "            dfUnLockedFile2['readOnly'].replace(['0', '0.0'], 'Not Locked', inplace=True)\n",
    "\n",
    "    df2 = pd.concat([dfUnLockedFile2, dfLockedFile, dfFolder], axis=0)\n",
    "        \n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a817acd8-1e83-4e17-8a15-c8de4f3117f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "PC = 14\n",
    "#DriveFoldersDEBUG(\"'Security Camera'\",'LEGAL/Legal Case')\n",
    "DriveFolders(\"'Twitter Violence Threat'\",'LEGAL/Legal Case/Laptop Screenshots')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52792948-8629-4a73-926f-aebbac198e76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a59deab1-c279-4842-ab4e-ffeef5f34afe",
   "metadata": {
    "tags": []
   },
   "source": [
    "### ***Verifies and Reports Files and Folders***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ae028f-2ea4-449c-bef7-bb5a09cac916",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DriveFolders(FolderName,Path):\n",
    "    query = \"mimeType = 'application/vnd.google-apps.folder' and name = \" + FolderName\n",
    "\n",
    "    from time import mktime\n",
    "    import datetime\n",
    "    from datetime import datetime\n",
    "    import os.path\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    from google.auth.transport.requests import Request\n",
    "    from google.oauth2.credentials import Credentials\n",
    "    from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "    from googleapiclient.discovery import build\n",
    "    from googleapiclient.errors import HttpError\n",
    "    import os\n",
    "    import subprocess\n",
    "    import time\n",
    "    global dffilecount, filename, foldersize, folderid, FolderName2, Locked, File_Type\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "    \n",
    "    currentDateTime = datetime.now()\n",
    "    date = currentDateTime.date()\n",
    "    year = date.strftime(\"%Y\") #except: 2022\n",
    "    date.strftime(\"%Y\")\n",
    "\n",
    "    d = datetime.now()\n",
    "    only_date, only_time = d.date(), d.time()\n",
    "    only_date = only_date.strftime('%Y.%m.%d')\n",
    "    only_time = only_time.strftime('%H.%M')\n",
    "    procTS = str(only_date) + \"_\" + str(only_time)\n",
    "    dffilecount = 0\n",
    "    FolderName2 = FolderName.replace(\"'\", \"\")\n",
    "    \n",
    "    if PC == 13:\n",
    "        Base = \"/Volumes/My Passport for Mac/Evidence/5 - Mobile Graphic & Video Media/\"\n",
    "        Local = \"/Users/rommell/Desktop/L - Civil Suit/RICO Album Tables/\"\n",
    "        External = \"/Volumes/My Passport for Mac/Evidence/5 - Media Documentation/\"\n",
    "\n",
    "    if PC == 14:\n",
    "        Base = \"/Volumes/Files/2022 MacBook Pro/LARGE FOLDERS/Civil Suit & Evidence/Civil Suit*/5 - Mobile Graphic & Video Media/11.17.24 RICO at Hip/\"\n",
    "        Local = \"/Users/rommellmontenegro/Desktop/Civil Suit*/5 - Mobile Graphic & Video Media/RICO Album Tables/Combine/Google Files/\"\n",
    "        External = \"/Volumes/Files/2022 MacBook Pro/LARGE FOLDERS/Civil Suit & Evidence/Civil Suit*/5 - Mobile Graphic & Video Media/FILES TABLES/\"\n",
    "\n",
    "    # If modifying these scopes, delete the file token.json.\n",
    "    SCOPES = ['https://www.googleapis.com/auth/spreadsheets', 'https://www.googleapis.com/auth/drive']\n",
    "\n",
    "    files = []\n",
    "\n",
    "    creds = None\n",
    "      # The file token.json stores the user's access and refresh tokens, and is\n",
    "      # created automatically when the authorization flow completes for the first\n",
    "      # time.\n",
    "    if os.path.exists(\"token.json\"):\n",
    "        creds = Credentials.from_authorized_user_file(\"token.json\", SCOPES)\n",
    "      # If there are no (valid) credentials available, let the user log in.\n",
    "    if not creds or not creds.valid:\n",
    "        if creds and creds.expired and creds.refresh_token:\n",
    "          creds.refresh(Request())\n",
    "        else:\n",
    "          flow = InstalledAppFlow.from_client_secrets_file(\n",
    "              \"client_secret_833249459653-01pcjla0c9re30fgr2dfipcgg5lgq6j0.apps.googleusercontent.com.json\", SCOPES\n",
    "          )\n",
    "          creds = flow.run_local_server(port=0)\n",
    "        # Save the credentials for the next run\n",
    "        with open(\"token.json\", \"w\") as token:\n",
    "          token.write(creds.to_json())\n",
    "\n",
    "    # Call the Drive v3 API\n",
    "    drive = build(\"drive\", \"v3\", credentials=creds)\n",
    "\n",
    "    # First, get the folder ID by querying by mimeType and name\n",
    "    folderId = drive.files().list(q = query, pageSize=1000, fields=\"nextPageToken,files(id, name,webViewLink,size,contentRestrictions)\").execute()\n",
    "\n",
    "    # this gives us a list of all folders with that name\n",
    "    folderIdResult = folderId.get('files', [])\n",
    "    # however, we know there is only 1 folder with that name, so we just get the id of the 1st item in the list\n",
    "    id = folderIdResult[0].get('id')\n",
    "    folderid = pd.Series(id)\n",
    "    \n",
    "    # Now, using the folder ID gotten above, we get all the files from that particular folder in a dictionary file of the resulting file id, name, and weblink FOR ONLY the first 1000 results.\n",
    "    results = drive.files().list(q = \"'\" + id + \"' in parents\", pageSize=1000, fields=\"nextPageToken, files(id, name,webViewLink,size,contentRestrictions)\").execute()\n",
    "\n",
    "    #Creates in a smaller dictionary file with only the data of file id, name, and weblink which can be made into a dataframe object.\n",
    "    items = results.get('files', [])\n",
    "    \n",
    "    page_token = None\n",
    "    while True:\n",
    "    # Now, using the folder ID gotten above, we get all the files from that particular folder in a dictionary file of the resulting file id, name, and weblink results.\n",
    "      response = (\n",
    "          drive.files()\n",
    "          .list(\n",
    "              q= \"'\" + id + \"' in parents\",\n",
    "              #q=\"mimeType = 'application/vnd.google-apps.folder'\",\n",
    "              spaces=\"drive\",\n",
    "              fields=\"nextPageToken, files(id, name, webViewLink, size, contentRestrictions)\",\n",
    "              pageToken=page_token,\n",
    "          )\n",
    "          .execute()\n",
    "      )\n",
    "        \n",
    "#       response = drive.files().get(fileId=\"FILE_ID\", fields = \"contentRestrictions\").execute(); \n",
    "        \n",
    "    #Creates in a smaller dictionary file with only the data of file id, name, and weblink which can be made into a dataframe object.\n",
    "      for file in response.get(\"files\", []):\n",
    "        items.append(file)\n",
    "      files.extend(response.get(\"files\", []))\n",
    "    \n",
    "      page_token = response.get(\"nextPageToken\", None)\n",
    "      if page_token is None:\n",
    "        break\n",
    "        \n",
    "    #Creates the dataframe of the results\n",
    "    \n",
    "#    df = pd.DataFrame(items)\n",
    "    df = pd.DataFrame(items, columns=['id', 'name', 'webViewLink', 'contentRestrictions', 'size','urlparts','ObjectType','readOnly'])\n",
    "    df = df[df['name'] != '.DS_Store']\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df.fillna(0, inplace=True)\n",
    "    if 'size' not in df.columns:\n",
    "        df['size'] = 0\n",
    "    if 'urlparts' not in df.columns:\n",
    "        df['urlparts'] = np.nan\n",
    "        df['urlparts'] = df['urlparts'].astype(str)\n",
    "    df['size'] = df['size'].astype(int)\n",
    "    foldersum = df['size'].sum()\n",
    "    if 'ObjectType' not in df.columns:    \n",
    "        df['ObjectType'] = ''\n",
    "    if 'readOnly' not in df.columns:    \n",
    "        df['readOnly'] = ''\n",
    "\n",
    "    df = df\n",
    "    df['ObjectType'] = df.ObjectType.astype(str)\n",
    "    df['urlparts'] = df['webViewLink'].str.split(\"/\")\n",
    "    df['urlparts'] = df.urlparts.astype(str)\n",
    "    df['urlparts'] = df['urlparts']\n",
    "    df['urlparts'] = df['urlparts'].tolist()\n",
    "    df['urlparts4'] = df['urlparts'].apply(lambda x: x[45:52]).astype(str)\n",
    "    df['urlparts4'] = df.urlparts4.astype(str)\n",
    "    df['urlparts3'] = df['urlparts'].apply(lambda x: x[36:40])\n",
    "    df['urlparts3'] = df['urlparts3'].astype(str)    \n",
    "    df['ObjectType'] = df['ObjectType'].astype(str)\n",
    "\n",
    "    conditions1 = [\n",
    "    df['urlparts4'] == 'folders',\n",
    "    df['urlparts3'] == 'file',\n",
    "    df['urlparts3'] == 'prea']\n",
    "    choices1 = ['Folder', 'File', 'File']\n",
    "    df['ObjectType'] = np.select(conditions1, choices1, default='')\n",
    "\n",
    "    if 'contentRestrictions' in df.columns:\n",
    "        for index, row in df.iterrows():\n",
    "            if row['ObjectType'] == 'File':\n",
    "                try: df['readOnly'] = df['contentRestrictions'][0][0].get(\"readOnly\")\n",
    "                except IndexError:\n",
    "                     if pd.isna(row['readOnly'])==True:\n",
    "                        df['readOnly'] = 'Unlocked'  \n",
    "                except KeyError:\n",
    "                    if pd.isna(row['readOnly'])==True:\n",
    "                        df['readOnly'] = 'Unlocked'\n",
    "                except TypeError: \n",
    "                    if pd.isna(row['readOnly'])==True:\n",
    "                        df['readOnly'] = 'Unlocked'\n",
    "                except HttpError:\n",
    "                    if pd.isna(row['readOnly'])==True:\n",
    "                        df['readOnly'] = 'Unlocked'\n",
    "                        \n",
    "    df['contentRestrictions'].replace(['0', '0.0'], 'Unlocked', inplace=True)\n",
    "    df['contentRestrictions'] = df['contentRestrictions'].astype(str)\n",
    "    df['readOnly'] = df['contentRestrictions'].apply(lambda x: x[:1]).astype(str)\n",
    "\n",
    "    dfFolder = pd.DataFrame(columns=['id', 'name', 'webViewLink', 'contentRestrictions', 'size','urlparts','ObjectType','readOnly'])\n",
    "    for index, row in df.iterrows():\n",
    "        if row['ObjectType'] == 'Folder':\n",
    "            dfFolder = df[df[\"ObjectType\"] == 'Folder']\n",
    "            dfFolder['readOnly'].replace(['0', '0.0'], 'Folder', inplace=True)\n",
    "\n",
    "    dfLockedFile = pd.DataFrame(columns=['id', 'name', 'webViewLink', 'contentRestrictions', 'size','urlparts','ObjectType','readOnly'])\n",
    "    for index, row in df.iterrows():\n",
    "        if row['ObjectType'] == 'File' and row['readOnly'] == '[':\n",
    "            dfLockedFile = df[df['readOnly'] == '[']\n",
    "            dfLockedFile['readOnly'].replace('[', 'Locked', inplace=True)\n",
    "    \n",
    "    dfUnLockedFile2 = pd.DataFrame(columns=['id', 'name', 'webViewLink', 'contentRestrictions', 'size','urlparts','ObjectType','readOnly'])    \n",
    "    for index, row in df.iterrows():\n",
    "        if row['ObjectType'] == 'File' and row['readOnly'] == '0':\n",
    "            dfUnLockedFile = df\n",
    "            dfUnLockedFile1 = dfUnLockedFile[dfUnLockedFile['readOnly'] == '0']\n",
    "            dfUnLockedFile2 = dfUnLockedFile1[dfUnLockedFile1['ObjectType'] == 'File']            \n",
    "            dfUnLockedFile2['readOnly'].replace(['0', '0.0'], 'Not Locked', inplace=True)\n",
    "\n",
    "    df2 = pd.concat([dfUnLockedFile2, dfLockedFile, dfFolder], axis=0)\n",
    "        \n",
    "    df2 = df2.drop(['urlparts', 'urlparts3', 'urlparts4', 'contentRestrictions'], axis=1)\n",
    "    df2 = df2.drop_duplicates()\n",
    "    df2 = df2.sort_values(by=['ObjectType','readOnly'], ascending=[False, True])\n",
    "    df2.reset_index(drop=True, inplace=True)\n",
    "    df = df2\n",
    "    \n",
    "    if 'name' not in df.columns:\n",
    "        df['name'] = np.nan\n",
    "        df = df[df.name != '.DS_Store']\n",
    "#    df.drop(df.loc[df['name']=='.DS_Store'].index, inplace=True)\n",
    "#    df.drop(df[df['name'] == '.DS_Store'].index, inplace=True)\n",
    "    dffilecount = str(len(df))\n",
    "\n",
    "    #df = df.sort_values(by='size')\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df['Folder'] = FolderName2\n",
    "    df['date-time processed'] = procTS\n",
    "    if 'size' not in df.columns:\n",
    "        df['size'] = np.nan\n",
    "    if 'readOnly' not in df.columns:\n",
    "        df['readOnly'] = \"Check\"\n",
    "    df['size'] = df['size'].fillna(0)\n",
    "    df['size'] = df['size'].astype(int)\n",
    "    foldersize = df['size'].sum()\n",
    "    df['MB_size'] = df['size']/1000000\n",
    "    \n",
    "    df['path'] = Path\n",
    "    df['Locked'] = df['readOnly']\n",
    "    Locked = df['Locked']\n",
    "\n",
    "    df['File Type'] = np.where(df['size'] == 0, 'Folder', df['name'].str[-4:])\n",
    "    df['File Type'].replace('conf', '.conf', inplace=True)\n",
    "    df['File Type'].replace('docx', '.docx', inplace=True)\n",
    "    df['File Type'].replace('heic', '.heic', inplace=True)\n",
    "    df['File Type'].replace('HEIC', '.heic', inplace=True)\n",
    "    df['File Type'].replace('html', '.html', inplace=True)     \n",
    "    df['File Type'].replace('JPG', '.jpeg', inplace=True)\n",
    "    df['File Type'].replace('JPEG', '.jpeg', inplace=True)\n",
    "    df['File Type'].replace('.JPG', '.jpeg', inplace=True)\n",
    "    df['File Type'].replace('.jpg', '.jpeg', inplace=True)\n",
    "    df['File Type'].replace('jpeg', '.jpeg', inplace=True)\n",
    "    df['File Type'].replace('.MOV', '.mov', inplace=True)\n",
    "    df['File Type'].replace('.PNG', '.png', inplace=True)\n",
    "    df['File Type'].replace('xlsm', '.xlsm', inplace=True)  \n",
    "    df['File Type'].replace('xlsx', '.xlsx', inplace=True)\n",
    "    File_Type = df['File Type']\n",
    "    unique_names = df['File Type'].unique()\n",
    "    \n",
    "    column_order = ['name', 'id', 'webViewLink', 'File Type', 'date-time processed', 'MB_size','Folder', 'path', 'Locked']\n",
    "    tabname = FolderName2[:30]\n",
    "    suffix = \"_GDrive_Files.xlsx\"\n",
    "    filename = only_date + \"_\" + only_time + \"_\" + FolderName2 + \"_(\" + dffilecount + \")\" + suffix\n",
    "    des = Local + only_date + \"/\"\n",
    "    \n",
    "    if not os.path.exists(des):\n",
    "        os.makedirs(des)\n",
    "    \n",
    "    HD_Dest = des + filename\n",
    "    Ext_Dest = External + filename\n",
    "    warnings.filterwarnings('ignore')\n",
    "    with pd.ExcelWriter(HD_Dest) as writer:\n",
    "        df[column_order].to_excel(writer, sheet_name=tabname)\n",
    "        \n",
    "    return dffilecount, filename, foldersize, folderid, FolderName2, File_Type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b904a5c3-c057-4a13-b42a-c4b4fbd0bc69",
   "metadata": {},
   "source": [
    "### ***Creates Tables... of Verified Files, of Verified Folders, and of Errors for Review***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48bd265-218d-43cd-a423-f98fff2b28ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Createtables():\n",
    "    #Cycles Through Folders to Create Tables of Verified Folders and Errors for Review\n",
    "    import pandas as pd\n",
    "    from google.auth.transport.requests import Request\n",
    "    from google.oauth2.credentials import Credentials\n",
    "    from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "    from googleapiclient.discovery import build\n",
    "    from googleapiclient.errors import HttpError\n",
    "    from time import mktime\n",
    "    import datetime\n",
    "    from datetime import datetime\n",
    "    import statistics\n",
    "    import inspect\n",
    "    import warnings\n",
    "    \n",
    "    d = datetime.now()\n",
    "    only_date, only_time = d.date(), d.time()\n",
    "    only_date = only_date.strftime('%Y.%m.%d')\n",
    "    only_time = only_time.strftime('%H.%M')\n",
    "    starttime = datetime.now()\n",
    "    \n",
    "    Errorsdf = pd.DataFrame()\n",
    "    foldersdf = pd.DataFrame()\n",
    "    \n",
    "    errorwebViewLinks = []\n",
    "    errorPaths = []\n",
    "    Paths = []\n",
    "    webViewLinks = []\n",
    "    ids = []\n",
    "    sizes = []\n",
    "    \n",
    "    names = pd.Series()\n",
    "    filenames = pd.Series()\n",
    "    Counts = pd.Series()\n",
    "    Errors = pd.Series()\n",
    "    \n",
    "    Errortypes = pd.Series()\n",
    "    ErrorIssues = pd.Series()\n",
    "    File_Types = []\n",
    "    \n",
    "    PC = 14\n",
    "    ftotal = 0\n",
    "    ProcRates = []\n",
    "    Procper = 0\n",
    "    \n",
    "    for index, row in folderdf.iterrows():\n",
    "        FolderName = row['name']\n",
    "        Path = row['path']\n",
    "        webViewLink = row['webViewLink']\n",
    "        gid = row['id']\n",
    "        \n",
    "        Total = len(folderdf)\n",
    "        TotalR = str(Total)\n",
    "        ftotal += 1\n",
    "    \n",
    "        FolderName = \"'\" + FolderName + \"'\"\n",
    "        PC = 14\n",
    "            \n",
    "        try: DriveFolders(FolderName,Path)\n",
    "        \n",
    "        except KeyError:\n",
    "            Errors = pd.concat([Errors, pd.Series(FolderName)])\n",
    "            Errortypes = pd.concat([Errortypes, pd.Series(\"KeyError\")])         \n",
    "            ErrorIssues = pd.concat([ErrorIssues, pd.Series(\"Missing a Column\")])          \n",
    "            errorwebViewLinks += [webViewLink]\n",
    "            errorPaths += [Path]\n",
    "    \n",
    "        except IndexError:\n",
    "            Errors = pd.concat([Errors, pd.Series(FolderName)])\n",
    "            Errortypes = pd.concat([Errortypes, pd.Series(\"IndexError\")]) \n",
    "            ErrorIssues = pd.concat([ErrorIssues, pd.Series(\"Row Doesn't Exist\")])          \n",
    "            errorwebViewLinks += [webViewLink]\n",
    "            errorPaths += [Path] \n",
    "            \n",
    "        except HttpError:\n",
    "            Errors = pd.concat([Errors, pd.Series(FolderName)])\n",
    "            Errortypes = pd.concat([Errortypes, pd.Series(\"HttpError\")]) \n",
    "            ErrorIssues = pd.concat([ErrorIssues, pd.Series(\"Folder Doesn't Exist\")])         \n",
    "            errorwebViewLinks += [webViewLink]\n",
    "            errorPaths += [Path]\n",
    "            \n",
    "    #    except AttributeError:        \n",
    "    #        Errors = pd.concat([Errors, pd.Series(FolderName)])\n",
    "    #        Errortype = \"AttributeError\"\n",
    "    #        Errortypes = pd.concat([Errortypes, pd.Series(Errortype)])\n",
    "    #        \n",
    "    #        ErrorIssue = \"In Trash\"\n",
    "    #        ErrorIssues = pd.concat([ErrorIssues, pd.Series(ErrorIssue)])\n",
    "    #        \n",
    "    #        errorwebViewLinks = pd.concat([errorwebViewLinks, pd.Series(webViewLink)]) \n",
    "    #        errorPaths = pd.concat([errorPaths, pd.Series(Path)]) \n",
    "    \n",
    "        if FolderName not in Errors:\n",
    "            Counts = pd.concat([Counts, pd.Series(dffilecount)])\n",
    "            filenames = pd.concat([filenames, pd.Series(filename)])\n",
    "            names = pd.concat([names, pd.Series(FolderName2)])      \n",
    "            File_Types += [File_Type]  \n",
    "            ids += [gid]\n",
    "            Paths += [Path]\n",
    "            webViewLinks += [webViewLink]                      \n",
    "            sizes += [foldersize]\n",
    "            \n",
    "        processtime = (datetime.now() - starttime).total_seconds()\n",
    "        if processtime > 3600:\n",
    "            processtimeR = str(round(processtime/3600,0)) + ' Hour(s) and ' + str(round((processtime%3600)*60,2)) + ' Minutes'\n",
    "        elif processtime > 60:\n",
    "            processtimeR = str(round(processtime/60,2)) + ' Minutes'\n",
    "        else:\n",
    "            processtimeR = str(round(processtime,2)) + ' Seconds'\n",
    "    \n",
    "        ProcRate = ftotal/(processtime)\n",
    "        ProcRateR = round(ProcRate,2)\n",
    "        ProcRates.append(ProcRate)\n",
    "    \n",
    "        try: AVGProcRateR = round(sum(ProcRates) / len(ProcRates),2) \n",
    "        except ZeroDivisionError: AVGProcRateR = round(sum(ProcRates) / 1 ,2)\n",
    "    \n",
    "        Procremaining = Total - ftotal\n",
    "        Procper = ftotal/Total\n",
    "        ProcperR = round(Procper*100,2)\n",
    "        try: Timeremaining = round(Procremaining/statistics.mean(ProcRates),2)\n",
    "        except ZeroDivisionError: Timeremaining = round((Procremaining/1),2)\n",
    "    \n",
    "        if Timeremaining > 7200:\n",
    "            TimeremainingR = str(round(Timeremaining/3600,0)) + ' Hour(s) and ' + str(abs(round((Timeremaining-(round(Timeremaining/3600,0)*3600))/60,2))) + ' Minutes'\n",
    "        elif Timeremaining > 3600:\n",
    "            TimeremainingR = str(round(Timeremaining/3600,0)) + ' Hour(s) and ' + str(round((Timeremaining%3600)*60,2)) + ' Minutes'\n",
    "        elif Timeremaining > 60:\n",
    "            TimeremainingR = str(round(Timeremaining/60,2)) + ' Minutes'\n",
    "        else:\n",
    "            TimeremainingR = str(round(Timeremaining,2)) + ' Seconds'\n",
    "    \n",
    "        print(\"Processed \" + str(ftotal) + \" files in \" + processtimeR + \". \" + str(ProcperR) + \"% completed of \" + TotalR + \" and \"+ TimeremainingR + ' left at ' + \n",
    "              str(d.strftime(\"%H:%M:%S\")) + \".                                              \", end=\"\\r\")\n",
    "        warnings.filterwarnings('ignore')\n",
    "            \n",
    "    Errorsdf['Folder with Error'] = Errors\n",
    "    Errorsdf['Errortype'] = Errortypes\n",
    "    Errorsdf['ErrorIssue'] = ErrorIssues\n",
    "    Errorsdf['Path'] = errorPaths\n",
    "    Errorsdf['webViewLink'] = errorwebViewLinks\n",
    "    \n",
    "    Local = \"/Users/rommellmontenegro/Desktop/Civil Suit*/5 - Mobile Graphic & Video Media/RICO Album Tables/Combine/Google Files/\"\n",
    "    errordes = Local + \"Errors/\"\n",
    "    \n",
    "    Local = \"/Users/rommellmontenegro/Desktop/Civil Suit*/5 - Mobile Graphic & Video Media/RICO Album Tables/Combine/Google Files/\"\n",
    "    errordes = Local + \"Errors/\"\n",
    "    \n",
    "    if not os.path.exists(errordes):\n",
    "        os.makedirs(errordes)\n",
    "        \n",
    "    source_code = inspect.getsource(DriveFolders)\n",
    "    \n",
    "    with open(errordes + only_date + \" \" + only_time + \" DriveFolders Code.txt\", 'w') as file:\n",
    "        file.write(source_code)\n",
    "    \n",
    "    with open(errordes + only_date + \" \" + only_time + \" DriveFolders Code.txt\", 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    data = []\n",
    "    for line in lines:\n",
    "        # Process each line and extract the data\n",
    "        row = line\n",
    "        data.append(row)\n",
    "    \n",
    "    funcdf = pd.DataFrame(data)\n",
    "\n",
    "    source_code2 = inspect.getsource(Createtables)\n",
    "    \n",
    "    with open(errordes + only_date + \" \" + only_time + \" Createtables Code.txt\", 'w') as file:\n",
    "        file.write(source_code2)\n",
    "    \n",
    "    with open(errordes + only_date + \" \" + only_time + \" Createtables Code.txt\", 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    data = []\n",
    "    for line in lines:\n",
    "        # Process each line and extract the data\n",
    "        row = line\n",
    "        data.append(row)\n",
    "    \n",
    "    createdf = pd.DataFrame(data)\n",
    "    \n",
    "    if len(Errorsdf) > 0:\n",
    "        tabname = 'Errors 1'\n",
    "        functabname = 'DriveFolders definition'\n",
    "        Createtabname = 'Createtables definition'\n",
    "        \n",
    "        suffix = \"_GDrive_Folders.xlsx\"\n",
    "        errorfilename = only_date + \"_\" + only_time + \"_\" + tabname + suffix\n",
    "        HD_Dest = errordes + errorfilename\n",
    "        \n",
    "        with pd.ExcelWriter(HD_Dest) as writer:\n",
    "            Errorsdf.to_excel(writer, sheet_name=tabname)\n",
    "            funcdf.to_excel(writer, sheet_name=functabname)\n",
    "            createdf.to_excel(writer, sheet_name=Createtabname)            \n",
    "        \n",
    "    foldersdf['count'] = Counts\n",
    "    foldersdf['count'] = foldersdf['count'].astype(int)\n",
    "    foldersdf['filename'] = filenames\n",
    "    foldersdf['name'] = names\n",
    "    \n",
    "    foldersdf['id'] = ids\n",
    "    foldersdf['webViewLink'] = webViewLinks\n",
    "    foldersdf['File Type'] = \"Folder\"                         \n",
    "    \n",
    "    foldersdf['path'] = Paths\n",
    "    \n",
    "    foldersdf['MB_size'] = sizes\n",
    "    foldersdf['MB_size'] = foldersdf['MB_size'].fillna(0)\n",
    "    foldersdf['MB_size'] = foldersdf['MB_size'].astype(float)\n",
    "    foldersdf['MB_size'] = foldersdf['MB_size']/1000000\n",
    "    \n",
    "    foldersdf = foldersdf.sort_values(by='path')\n",
    "    foldersdf.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    suffix = \"_GDrive_Folders.xlsx\"\n",
    "    \n",
    "    Local = \"/Users/rommellmontenegro/Desktop/Civil Suit*/5 - Mobile Graphic & Video Media/RICO Album Tables/Combine/Google Files/\"\n",
    "    des = Local + \"Validated/\"\n",
    "    \n",
    "    if not os.path.exists(des):\n",
    "        os.makedirs(des)\n",
    "    \n",
    "    tabname = 'Validated 1'\n",
    "    R2Cfilename = only_date + \"_\" + only_time + \"_\" + tabname + suffix\n",
    "    HD_Dest = des + R2Cfilename\n",
    "    \n",
    "    with pd.ExcelWriter(HD_Dest) as writer:\n",
    "        foldersdf.to_excel(writer, sheet_name=tabname)\n",
    "    warnings.filterwarnings('ignore')\n",
    "    \n",
    "    return foldersdf\n",
    "\n",
    "Createtables()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2aa99f-f6d8-41aa-ad81-be485879dd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "FolderName"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a706c0c3-5f6f-430d-bec7-5b4d650162bd",
   "metadata": {},
   "source": [
    "# One Off Folder Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2634b54-2848-41f4-844c-89f43028fb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DriveFolder1(FolderName,Path):\n",
    "    query = \"mimeType = 'application/vnd.google-apps.folder' and name = \" + FolderName\n",
    "\n",
    "    from time import mktime\n",
    "    import datetime\n",
    "    from datetime import datetime\n",
    "    import os.path\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    from google.auth.transport.requests import Request\n",
    "    from google.oauth2.credentials import Credentials\n",
    "    from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "    from googleapiclient.discovery import build\n",
    "    from googleapiclient.errors import HttpError\n",
    "    import os\n",
    "    import subprocess\n",
    "    import time\n",
    "    global dffilecount, filename, foldersize, folderid, FolderName2, Locked, File_Type\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "    \n",
    "    currentDateTime = datetime.now()\n",
    "    date = currentDateTime.date()\n",
    "    year = date.strftime(\"%Y\") #except: 2022\n",
    "    date.strftime(\"%Y\")\n",
    "\n",
    "    d = datetime.now()\n",
    "    only_date, only_time = d.date(), d.time()\n",
    "    only_date = only_date.strftime('%Y.%m.%d')\n",
    "    only_time = only_time.strftime('%H.%M')\n",
    "    procTS = str(only_date) + \"_\" + str(only_time)\n",
    "    dffilecount = 0\n",
    "    FolderName2 = FolderName.replace(\"'\", \"\")\n",
    "    \n",
    "    if PC == 13:\n",
    "        Base = \"/Volumes/My Passport for Mac/Evidence/5 - Mobile Graphic & Video Media/\"\n",
    "        Local = \"/Users/rommell/Desktop/L - Civil Suit/RICO Album Tables/\"\n",
    "        External = \"/Volumes/My Passport for Mac/Evidence/5 - Media Documentation/\"\n",
    "\n",
    "    if PC == 14:\n",
    "        Base = \"/Volumes/Files/2022 MacBook Pro/LARGE FOLDERS/Civil Suit & Evidence/Civil Suit*/5 - Mobile Graphic & Video Media/11.17.24 RICO at Hip/\"\n",
    "        Local = \"/Users/rommellmontenegro/Desktop/Civil Suit*/5 - Mobile Graphic & Video Media/RICO Album Tables/Combine/Google Files/\"\n",
    "        External = \"/Volumes/Files/2022 MacBook Pro/LARGE FOLDERS/Civil Suit & Evidence/Civil Suit*/5 - Mobile Graphic & Video Media/FILES TABLES/\"\n",
    "\n",
    "    # If modifying these scopes, delete the file token.json.\n",
    "    SCOPES = ['https://www.googleapis.com/auth/spreadsheets', 'https://www.googleapis.com/auth/drive']\n",
    "\n",
    "    files = []\n",
    "\n",
    "    creds = None\n",
    "      # The file token.json stores the user's access and refresh tokens, and is\n",
    "      # created automatically when the authorization flow completes for the first\n",
    "      # time.\n",
    "    if os.path.exists(\"token.json\"):\n",
    "        creds = Credentials.from_authorized_user_file(\"token.json\", SCOPES)\n",
    "      # If there are no (valid) credentials available, let the user log in.\n",
    "    if not creds or not creds.valid:\n",
    "        if creds and creds.expired and creds.refresh_token:\n",
    "          creds.refresh(Request())\n",
    "        else:\n",
    "          flow = InstalledAppFlow.from_client_secrets_file(\n",
    "              \"client_secret_833249459653-01pcjla0c9re30fgr2dfipcgg5lgq6j0.apps.googleusercontent.com.json\", SCOPES\n",
    "          )\n",
    "          creds = flow.run_local_server(port=0)\n",
    "        # Save the credentials for the next run\n",
    "        with open(\"token.json\", \"w\") as token:\n",
    "          token.write(creds.to_json())\n",
    "\n",
    "    # Call the Drive v3 API\n",
    "    drive = build(\"drive\", \"v3\", credentials=creds)\n",
    "\n",
    "    # First, get the folder ID by querying by mimeType and name\n",
    "    folderId = drive.files().list(q = query, pageSize=1000, fields=\"nextPageToken,files(id, name,webViewLink,size,contentRestrictions)\").execute()\n",
    "\n",
    "    # this gives us a list of all folders with that name\n",
    "    folderIdResult = folderId.get('files', [])\n",
    "    # however, we know there is only 1 folder with that name, so we just get the id of the 1st item in the list\n",
    "    id = folderIdResult[0].get('id')\n",
    "    folderid = pd.Series(id)\n",
    "    \n",
    "    # Now, using the folder ID gotten above, we get all the files from that particular folder in a dictionary file of the resulting file id, name, and weblink FOR ONLY the first 1000 results.\n",
    "    results = drive.files().list(q = \"'\" + id + \"' in parents\", pageSize=1000, fields=\"nextPageToken, files(id, name,webViewLink,size,contentRestrictions)\").execute()\n",
    "\n",
    "    #Creates in a smaller dictionary file with only the data of file id, name, and weblink which can be made into a dataframe object.\n",
    "    items = results.get('files', [])\n",
    "    \n",
    "    page_token = None\n",
    "    while True:\n",
    "    # Now, using the folder ID gotten above, we get all the files from that particular folder in a dictionary file of the resulting file id, name, and weblink results.\n",
    "      response = (\n",
    "          drive.files()\n",
    "          .list(\n",
    "              q= \"'\" + id + \"' in parents\",\n",
    "              #q=\"mimeType = 'application/vnd.google-apps.folder'\",\n",
    "              spaces=\"drive\",\n",
    "              fields=\"nextPageToken, files(id, name, webViewLink, size, contentRestrictions)\",\n",
    "              pageToken=page_token,\n",
    "          )\n",
    "          .execute()\n",
    "      )\n",
    "        \n",
    "#       response = drive.files().get(fileId=\"FILE_ID\", fields = \"contentRestrictions\").execute(); \n",
    "        \n",
    "    #Creates in a smaller dictionary file with only the data of file id, name, and weblink which can be made into a dataframe object.\n",
    "      for file in response.get(\"files\", []):\n",
    "        items.append(file)\n",
    "      files.extend(response.get(\"files\", []))\n",
    "    \n",
    "      page_token = response.get(\"nextPageToken\", None)\n",
    "      if page_token is None:\n",
    "        break\n",
    "        \n",
    "    #Creates the dataframe of the results\n",
    "    \n",
    "#    df = pd.DataFrame(items)\n",
    "    df = pd.DataFrame(items, columns=['id', 'name', 'webViewLink', 'contentRestrictions', 'size','urlparts','ObjectType','readOnly'])\n",
    "    df = df[df['name'] != '.DS_Store']\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df.fillna(0, inplace=True)\n",
    "    if 'size' not in df.columns:\n",
    "        df['size'] = 0\n",
    "    if 'urlparts' not in df.columns:\n",
    "        df['urlparts'] = np.nan\n",
    "        df['urlparts'] = df['urlparts'].astype(str)\n",
    "    df['size'] = df['size'].astype(int)\n",
    "    foldersum = df['size'].sum()\n",
    "    if 'ObjectType' not in df.columns:    \n",
    "        df['ObjectType'] = ''\n",
    "    if 'readOnly' not in df.columns:    \n",
    "        df['readOnly'] = ''\n",
    "\n",
    "    df = df\n",
    "    df['ObjectType'] = df.ObjectType.astype(str)\n",
    "    df['urlparts'] = df['webViewLink'].str.split(\"/\")\n",
    "    df['urlparts'] = df.urlparts.astype(str)\n",
    "    df['urlparts'] = df['urlparts']\n",
    "    df['urlparts'] = df['urlparts'].tolist()\n",
    "    df['urlparts4'] = df['urlparts'].apply(lambda x: x[45:52]).astype(str)\n",
    "    df['urlparts4'] = df.urlparts4.astype(str)\n",
    "    df['urlparts3'] = df['urlparts'].apply(lambda x: x[36:40])\n",
    "    df['urlparts3'] = df['urlparts3'].astype(str)    \n",
    "    df['ObjectType'] = df['ObjectType'].astype(str)\n",
    "\n",
    "    conditions1 = [\n",
    "    df['urlparts4'] == 'folders',\n",
    "    df['urlparts3'] == 'file',\n",
    "    df['urlparts3'] == 'prea']\n",
    "    choices1 = ['Folder', 'File', 'File']\n",
    "    df['ObjectType'] = np.select(conditions1, choices1, default='')\n",
    "\n",
    "    if 'contentRestrictions' in df.columns:\n",
    "        for index, row in df.iterrows():\n",
    "            if row['ObjectType'] == 'File':\n",
    "                try: df['readOnly'] = df['contentRestrictions'][0][0].get(\"readOnly\")\n",
    "                except IndexError:\n",
    "                     if pd.isna(row['readOnly'])==True:\n",
    "                        df['readOnly'] = 'Unlocked'  \n",
    "                except KeyError:\n",
    "                    if pd.isna(row['readOnly'])==True:\n",
    "                        df['readOnly'] = 'Unlocked'\n",
    "                except TypeError: \n",
    "                    if pd.isna(row['readOnly'])==True:\n",
    "                        df['readOnly'] = 'Unlocked'\n",
    "                except HttpError:\n",
    "                    if pd.isna(row['readOnly'])==True:\n",
    "                        df['readOnly'] = 'Unlocked'\n",
    "                        \n",
    "    df['contentRestrictions'].replace(['0', '0.0'], 'Unlocked', inplace=True)\n",
    "    df['contentRestrictions'] = df['contentRestrictions'].astype(str)\n",
    "    df['readOnly'] = df['contentRestrictions'].apply(lambda x: x[:1]).astype(str)\n",
    "\n",
    "    dfFolder = pd.DataFrame(columns=['id', 'name', 'webViewLink', 'contentRestrictions', 'size','urlparts','ObjectType','readOnly'])\n",
    "    for index, row in df.iterrows():\n",
    "        if row['ObjectType'] == 'Folder':\n",
    "            dfFolder = df[df[\"ObjectType\"] == 'Folder']\n",
    "            dfFolder['readOnly'].replace(['0', '0.0'], 'Folder', inplace=True)\n",
    "\n",
    "    dfLockedFile = pd.DataFrame(columns=['id', 'name', 'webViewLink', 'contentRestrictions', 'size','urlparts','ObjectType','readOnly'])\n",
    "    for index, row in df.iterrows():\n",
    "        if row['ObjectType'] == 'File' and row['readOnly'] == '[':\n",
    "            dfLockedFile = df[df['readOnly'] == '[']\n",
    "            dfLockedFile['readOnly'].replace('[', 'Locked', inplace=True)\n",
    "    \n",
    "    dfUnLockedFile2 = pd.DataFrame(columns=['id', 'name', 'webViewLink', 'contentRestrictions', 'size','urlparts','ObjectType','readOnly'])    \n",
    "    for index, row in df.iterrows():\n",
    "        if row['ObjectType'] == 'File' and row['readOnly'] == '0':\n",
    "            dfUnLockedFile = df\n",
    "            dfUnLockedFile1 = dfUnLockedFile[dfUnLockedFile['readOnly'] == '0']\n",
    "            dfUnLockedFile2 = dfUnLockedFile1[dfUnLockedFile1['ObjectType'] == 'File']            \n",
    "            dfUnLockedFile2['readOnly'].replace(['0', '0.0'], 'Not Locked', inplace=True)\n",
    "\n",
    "    df2 = pd.concat([dfUnLockedFile2, dfLockedFile, dfFolder], axis=0)\n",
    "        \n",
    "    df2 = df2.drop(['urlparts', 'urlparts3', 'urlparts4', 'contentRestrictions'], axis=1)\n",
    "    df2 = df2.drop_duplicates()\n",
    "    df2 = df2.sort_values(by=['ObjectType','readOnly'], ascending=[False, True])\n",
    "    df2.reset_index(drop=True, inplace=True)\n",
    "    df = df2\n",
    "    \n",
    "    if 'name' not in df.columns:\n",
    "        df['name'] = np.nan\n",
    "        df = df[df.name != '.DS_Store']\n",
    "#    df.drop(df.loc[df['name']=='.DS_Store'].index, inplace=True)\n",
    "#    df.drop(df[df['name'] == '.DS_Store'].index, inplace=True)\n",
    "    dffilecount = str(len(df))\n",
    "\n",
    "    #df = df.sort_values(by='size')\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df['Folder'] = FolderName2\n",
    "    df['date-time processed'] = procTS\n",
    "    if 'size' not in df.columns:\n",
    "        df['size'] = np.nan\n",
    "    if 'readOnly' not in df.columns:\n",
    "        df['readOnly'] = \"Check\"\n",
    "    df['size'] = df['size'].fillna(0)\n",
    "    df['size'] = df['size'].astype(int)\n",
    "    foldersize = df['size'].sum()\n",
    "    df['MB_size'] = df['size']/1000000\n",
    "    \n",
    "    df['path'] = Path\n",
    "    df['Locked'] = df['readOnly']\n",
    "    Locked = df['Locked']\n",
    "\n",
    "    df['File Type'] = np.where(df['size'] == 0, 'Folder', df['name'].str[-4:])\n",
    "    df['File Type'].replace('conf', '.conf', inplace=True)\n",
    "    df['File Type'].replace('docx', '.docx', inplace=True)\n",
    "    df['File Type'].replace('heic', '.heic', inplace=True)\n",
    "    df['File Type'].replace('HEIC', '.heic', inplace=True)\n",
    "    df['File Type'].replace('html', '.html', inplace=True)     \n",
    "    df['File Type'].replace('JPG', '.jpeg', inplace=True)\n",
    "    df['File Type'].replace('JPEG', '.jpeg', inplace=True)\n",
    "    df['File Type'].replace('.JPG', '.jpeg', inplace=True)\n",
    "    df['File Type'].replace('.jpg', '.jpeg', inplace=True)\n",
    "    df['File Type'].replace('jpeg', '.jpeg', inplace=True)\n",
    "    df['File Type'].replace('.MOV', '.mov', inplace=True)\n",
    "    df['File Type'].replace('.PNG', '.png', inplace=True)\n",
    "    df['File Type'].replace('xlsm', '.xlsm', inplace=True)  \n",
    "    df['File Type'].replace('xlsx', '.xlsx', inplace=True)\n",
    "    File_Type = df['File Type']\n",
    "    unique_names = df['File Type'].unique()\n",
    "\n",
    "    OneDF = df[['name', 'id', 'webViewLink', 'File Type', 'date-time processed', 'MB_size','Folder', 'path', 'Locked']].copy()\n",
    "    \n",
    "    column_order = ['name', 'id', 'webViewLink', 'File Type', 'date-time processed', 'MB_size','Folder', 'path', 'Locked']\n",
    "    tabname = FolderName2[:30]\n",
    "    suffix = \"_GDrive_Files.xlsx\"\n",
    "    filename = only_date + \"_\" + only_time + \"_\" + FolderName2 + \"_(\" + dffilecount + \")\" + suffix\n",
    "    des = Local + only_date + \"/\"\n",
    "    \n",
    "    if not os.path.exists(des):\n",
    "        os.makedirs(des)\n",
    "    \n",
    "    HD_Dest = des + filename\n",
    "    Ext_Dest = External + filename\n",
    "    warnings.filterwarnings('ignore')\n",
    "    with pd.ExcelWriter(HD_Dest) as writer:\n",
    "        df[column_order].to_excel(writer, sheet_name=tabname)\n",
    "        \n",
    "    return OneDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "304edfe2-5177-4620-917e-cf03e3ec90ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>webViewLink</th>\n",
       "      <th>File Type</th>\n",
       "      <th>date-time processed</th>\n",
       "      <th>MB_size</th>\n",
       "      <th>Folder</th>\n",
       "      <th>path</th>\n",
       "      <th>Locked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Limited Medical, Legal, Police, &amp; Municipal Su...</td>\n",
       "      <td>1wKgBZHiEvQ4aFS61MStso77gKziMHEQd</td>\n",
       "      <td>https://drive.google.com/drive/folders/1wKgBZH...</td>\n",
       "      <td>Folder</td>\n",
       "      <td>2025.05.09_00.34</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Reports</td>\n",
       "      <td>LEGAL/Legal Case/</td>\n",
       "      <td>Folder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Manager Liability</td>\n",
       "      <td>1Cm4AoGbabhpoitAxaRALv9IETTQMaIWs</td>\n",
       "      <td>https://drive.google.com/drive/folders/1Cm4AoG...</td>\n",
       "      <td>Folder</td>\n",
       "      <td>2025.05.09_00.34</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Reports</td>\n",
       "      <td>LEGAL/Legal Case/</td>\n",
       "      <td>Folder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Losses</td>\n",
       "      <td>15Rza0jPYg3U-vJWkHVuTPU2OiM0gVmi1</td>\n",
       "      <td>https://drive.google.com/drive/folders/15Rza0j...</td>\n",
       "      <td>Folder</td>\n",
       "      <td>2025.05.09_00.34</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Reports</td>\n",
       "      <td>LEGAL/Legal Case/</td>\n",
       "      <td>Folder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Claims</td>\n",
       "      <td>1AC2_vPAWxhYRMwq7_uDrmeiqvOlTzkcs</td>\n",
       "      <td>https://drive.google.com/drive/folders/1AC2_vP...</td>\n",
       "      <td>Folder</td>\n",
       "      <td>2025.05.09_00.34</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Reports</td>\n",
       "      <td>LEGAL/Legal Case/</td>\n",
       "      <td>Folder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Summary Documents</td>\n",
       "      <td>13kPU7PKz7xQ2RixdrAUpIv3o6JVcgxKy</td>\n",
       "      <td>https://drive.google.com/drive/folders/13kPU7P...</td>\n",
       "      <td>Folder</td>\n",
       "      <td>2025.05.09_00.34</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Reports</td>\n",
       "      <td>LEGAL/Legal Case/</td>\n",
       "      <td>Folder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>List of all Files.xlsx</td>\n",
       "      <td>1PYu3JyrfNJY-ell8lrCCMtKWH0-S0vm-</td>\n",
       "      <td>https://docs.google.com/spreadsheets/d/1PYu3Jy...</td>\n",
       "      <td>.xlsx</td>\n",
       "      <td>2025.05.09_00.34</td>\n",
       "      <td>5.448211</td>\n",
       "      <td>Reports</td>\n",
       "      <td>LEGAL/Legal Case/</td>\n",
       "      <td>Locked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>List of all Folders.xlsx</td>\n",
       "      <td>1qPuliKc2bGoVc2ekfb737XRUQANVM3ml</td>\n",
       "      <td>https://docs.google.com/spreadsheets/d/1qPuliK...</td>\n",
       "      <td>.xlsx</td>\n",
       "      <td>2025.05.09_00.34</td>\n",
       "      <td>0.091805</td>\n",
       "      <td>Reports</td>\n",
       "      <td>LEGAL/Legal Case/</td>\n",
       "      <td>Locked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Concealment Tactics.pdf</td>\n",
       "      <td>1f9tQEDZ8KcnUEdD9JSKSR_Rw4GTXNVW8</td>\n",
       "      <td>https://drive.google.com/file/d/1f9tQEDZ8KcnUE...</td>\n",
       "      <td>.pdf</td>\n",
       "      <td>2025.05.09_00.34</td>\n",
       "      <td>0.214236</td>\n",
       "      <td>Reports</td>\n",
       "      <td>LEGAL/Legal Case/</td>\n",
       "      <td>Locked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cited Video &amp; Image Links.xlsx</td>\n",
       "      <td>15iYW8RetZtYhy69KgA2nPFueLm81kAoL</td>\n",
       "      <td>https://docs.google.com/spreadsheets/d/15iYW8R...</td>\n",
       "      <td>.xlsx</td>\n",
       "      <td>2025.05.09_00.34</td>\n",
       "      <td>11.295342</td>\n",
       "      <td>Reports</td>\n",
       "      <td>LEGAL/Legal Case/</td>\n",
       "      <td>Locked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Presentation Tabulation.xlsx</td>\n",
       "      <td>1JJruWEteV39YVAEG1qOPyUjqt56en35W</td>\n",
       "      <td>https://docs.google.com/spreadsheets/d/1JJruWE...</td>\n",
       "      <td>.xlsx</td>\n",
       "      <td>2025.05.09_00.34</td>\n",
       "      <td>34.597467</td>\n",
       "      <td>Reports</td>\n",
       "      <td>LEGAL/Legal Case/</td>\n",
       "      <td>Locked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Video and Image Links.xlsx</td>\n",
       "      <td>1h7HNgoPxc5z5kEFJ9oiLmPP_OQI3L3p5Q4xanmqmJls</td>\n",
       "      <td>https://docs.google.com/spreadsheets/d/1h7HNgo...</td>\n",
       "      <td>.xlsx</td>\n",
       "      <td>2025.05.09_00.34</td>\n",
       "      <td>2.337715</td>\n",
       "      <td>Reports</td>\n",
       "      <td>LEGAL/Legal Case/</td>\n",
       "      <td>Locked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>When Not How My Dog Died.pdf</td>\n",
       "      <td>1kWw7_t6-m5WDoz-c88MFrvtjfZdoF5iB</td>\n",
       "      <td>https://drive.google.com/file/d/1kWw7_t6-m5WDo...</td>\n",
       "      <td>.pdf</td>\n",
       "      <td>2025.05.09_00.34</td>\n",
       "      <td>3.735782</td>\n",
       "      <td>Reports</td>\n",
       "      <td>LEGAL/Legal Case/</td>\n",
       "      <td>Locked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Video Image Evidence Summary.pdf</td>\n",
       "      <td>1WlnsDPBLQatCUszGnI4Zt2R3OVd-lFZd</td>\n",
       "      <td>https://drive.google.com/file/d/1WlnsDPBLQatCU...</td>\n",
       "      <td>.pdf</td>\n",
       "      <td>2025.05.09_00.34</td>\n",
       "      <td>2.482857</td>\n",
       "      <td>Reports</td>\n",
       "      <td>LEGAL/Legal Case/</td>\n",
       "      <td>Locked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Summary.pdf</td>\n",
       "      <td>1As0L7kpIhLIirWCwaey_weRO2AsUrkxP</td>\n",
       "      <td>https://drive.google.com/file/d/1As0L7kpIhLIir...</td>\n",
       "      <td>.pdf</td>\n",
       "      <td>2025.05.09_00.34</td>\n",
       "      <td>0.189193</td>\n",
       "      <td>Reports</td>\n",
       "      <td>LEGAL/Legal Case/</td>\n",
       "      <td>Locked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Statement.pdf</td>\n",
       "      <td>1rmd-gBa42fwvmtMpf_NpNXXw7uqvj10n</td>\n",
       "      <td>https://drive.google.com/file/d/1rmd-gBa42fwvm...</td>\n",
       "      <td>.pdf</td>\n",
       "      <td>2025.05.09_00.34</td>\n",
       "      <td>7.999377</td>\n",
       "      <td>Reports</td>\n",
       "      <td>LEGAL/Legal Case/</td>\n",
       "      <td>Locked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Management Liability.pdf</td>\n",
       "      <td>1q0Y6cwyd9Kj3N5_KUFzart-nFV8k7Vrk</td>\n",
       "      <td>https://drive.google.com/file/d/1q0Y6cwyd9Kj3N...</td>\n",
       "      <td>.pdf</td>\n",
       "      <td>2025.05.09_00.34</td>\n",
       "      <td>1.393481</td>\n",
       "      <td>Reports</td>\n",
       "      <td>LEGAL/Legal Case/</td>\n",
       "      <td>Locked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>IP Theft Claim.pdf</td>\n",
       "      <td>1DMNzQ6S-e6bIqG3SOj8Il4wqO_balBJD</td>\n",
       "      <td>https://drive.google.com/file/d/1DMNzQ6S-e6bIq...</td>\n",
       "      <td>.pdf</td>\n",
       "      <td>2025.05.09_00.34</td>\n",
       "      <td>0.042605</td>\n",
       "      <td>Reports</td>\n",
       "      <td>LEGAL/Legal Case/</td>\n",
       "      <td>Locked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Infractions Related to Cease &amp; Desist.pdf</td>\n",
       "      <td>1IB_VWepWr2XLgXHofKm1BT1uroApmWeC</td>\n",
       "      <td>https://drive.google.com/file/d/1IB_VWepWr2XLg...</td>\n",
       "      <td>.pdf</td>\n",
       "      <td>2025.05.09_00.34</td>\n",
       "      <td>1.203893</td>\n",
       "      <td>Reports</td>\n",
       "      <td>LEGAL/Legal Case/</td>\n",
       "      <td>Locked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Illegal Entry Data.pdf</td>\n",
       "      <td>1ivuhZogU5bTUEinUQxB-NzOogffryzG3</td>\n",
       "      <td>https://drive.google.com/file/d/1ivuhZogU5bTUE...</td>\n",
       "      <td>.pdf</td>\n",
       "      <td>2025.05.09_00.34</td>\n",
       "      <td>0.056653</td>\n",
       "      <td>Reports</td>\n",
       "      <td>LEGAL/Legal Case/</td>\n",
       "      <td>Locked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Email Explanation.pdf</td>\n",
       "      <td>1fGfkUtBMMmeNrtIvwHgCsdpQoUqQE43g</td>\n",
       "      <td>https://drive.google.com/file/d/1fGfkUtBMMmeNr...</td>\n",
       "      <td>.pdf</td>\n",
       "      <td>2025.05.09_00.34</td>\n",
       "      <td>18.390025</td>\n",
       "      <td>Reports</td>\n",
       "      <td>LEGAL/Legal Case/</td>\n",
       "      <td>Locked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Car Expenses &amp; Analysis.pdf</td>\n",
       "      <td>1eKsx-QeH-pQt0pV_qmg5Ol2CtEMlQK3L</td>\n",
       "      <td>https://drive.google.com/file/d/1eKsx-QeH-pQt0...</td>\n",
       "      <td>.pdf</td>\n",
       "      <td>2025.05.09_00.34</td>\n",
       "      <td>53.414351</td>\n",
       "      <td>Reports</td>\n",
       "      <td>LEGAL/Legal Case/</td>\n",
       "      <td>Locked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Discrimination Records At HiP.pdf</td>\n",
       "      <td>1J5jSVTJGsiW8JD0cHPnl7bWmcRL92qYd</td>\n",
       "      <td>https://drive.google.com/file/d/1J5jSVTJGsiW8J...</td>\n",
       "      <td>.pdf</td>\n",
       "      <td>2025.05.09_00.34</td>\n",
       "      <td>0.232971</td>\n",
       "      <td>Reports</td>\n",
       "      <td>LEGAL/Legal Case/</td>\n",
       "      <td>Locked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Discrimination Records Before HiP.pdf</td>\n",
       "      <td>1YBdqwMyxb-aAvFAcTtSVwrUlvSyi_oEk</td>\n",
       "      <td>https://drive.google.com/file/d/1YBdqwMyxb-aAv...</td>\n",
       "      <td>.pdf</td>\n",
       "      <td>2025.05.09_00.34</td>\n",
       "      <td>0.228861</td>\n",
       "      <td>Reports</td>\n",
       "      <td>LEGAL/Legal Case/</td>\n",
       "      <td>Locked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Report of Losses At HiP.pdf</td>\n",
       "      <td>1PiptUpFauq1Zetx6cOnq8x8mJ8SXqeYi</td>\n",
       "      <td>https://drive.google.com/file/d/1PiptUpFauq1Ze...</td>\n",
       "      <td>.pdf</td>\n",
       "      <td>2025.05.09_00.34</td>\n",
       "      <td>0.228326</td>\n",
       "      <td>Reports</td>\n",
       "      <td>LEGAL/Legal Case/</td>\n",
       "      <td>Locked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Complaint.pdf</td>\n",
       "      <td>1YsWaPvVbzC65_SVyc-q8XD5fwgfT6ikA</td>\n",
       "      <td>https://drive.google.com/file/d/1YsWaPvVbzC65_...</td>\n",
       "      <td>.pdf</td>\n",
       "      <td>2025.05.09_00.34</td>\n",
       "      <td>0.118384</td>\n",
       "      <td>Reports</td>\n",
       "      <td>LEGAL/Legal Case/</td>\n",
       "      <td>Locked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Montenegro V BSC Exhibits.pdf</td>\n",
       "      <td>18W3Hmj2Zy0Ezzor8Djf3CoRqr2yzXZfa</td>\n",
       "      <td>https://drive.google.com/file/d/18W3Hmj2Zy0Ezz...</td>\n",
       "      <td>.pdf</td>\n",
       "      <td>2025.05.09_00.34</td>\n",
       "      <td>268.867196</td>\n",
       "      <td>Reports</td>\n",
       "      <td>LEGAL/Legal Case/</td>\n",
       "      <td>Not Locked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>List of All Files.xlsx</td>\n",
       "      <td>1dB0l97rUEc0DRZ8VaHCN4Jqr8S_zWQyT</td>\n",
       "      <td>https://docs.google.com/spreadsheets/d/1dB0l97...</td>\n",
       "      <td>.xlsx</td>\n",
       "      <td>2025.05.09_00.34</td>\n",
       "      <td>5.448211</td>\n",
       "      <td>Reports</td>\n",
       "      <td>LEGAL/Legal Case/</td>\n",
       "      <td>Not Locked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>List of All Folders.xlsx</td>\n",
       "      <td>1DogH_4Tx6MO0IqUuiPYg6NRTfNQw_Gbl</td>\n",
       "      <td>https://docs.google.com/spreadsheets/d/1DogH_4...</td>\n",
       "      <td>.xlsx</td>\n",
       "      <td>2025.05.09_00.34</td>\n",
       "      <td>0.091805</td>\n",
       "      <td>Reports</td>\n",
       "      <td>LEGAL/Legal Case/</td>\n",
       "      <td>Not Locked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5.3.25 Montenegro V BSC Exhibits.pdf</td>\n",
       "      <td>1WLNVVWx56IhYmPR-eSlRTBGgY4bsVu0t</td>\n",
       "      <td>https://drive.google.com/file/d/1WLNVVWx56IhYm...</td>\n",
       "      <td>.pdf</td>\n",
       "      <td>2025.05.09_00.34</td>\n",
       "      <td>268.726792</td>\n",
       "      <td>Reports</td>\n",
       "      <td>LEGAL/Legal Case/</td>\n",
       "      <td>Not Locked</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 name  \\\n",
       "0   Limited Medical, Legal, Police, & Municipal Su...   \n",
       "1                                   Manager Liability   \n",
       "2                                              Losses   \n",
       "3                                              Claims   \n",
       "4                                   Summary Documents   \n",
       "5                              List of all Files.xlsx   \n",
       "6                            List of all Folders.xlsx   \n",
       "7                             Concealment Tactics.pdf   \n",
       "8                      Cited Video & Image Links.xlsx   \n",
       "9                        Presentation Tabulation.xlsx   \n",
       "10                         Video and Image Links.xlsx   \n",
       "11                       When Not How My Dog Died.pdf   \n",
       "12                   Video Image Evidence Summary.pdf   \n",
       "13                                        Summary.pdf   \n",
       "14                                      Statement.pdf   \n",
       "15                           Management Liability.pdf   \n",
       "16                                 IP Theft Claim.pdf   \n",
       "17          Infractions Related to Cease & Desist.pdf   \n",
       "18                             Illegal Entry Data.pdf   \n",
       "19                              Email Explanation.pdf   \n",
       "20                        Car Expenses & Analysis.pdf   \n",
       "21                  Discrimination Records At HiP.pdf   \n",
       "22              Discrimination Records Before HiP.pdf   \n",
       "23                        Report of Losses At HiP.pdf   \n",
       "24                                      Complaint.pdf   \n",
       "25                      Montenegro V BSC Exhibits.pdf   \n",
       "26                             List of All Files.xlsx   \n",
       "27                           List of All Folders.xlsx   \n",
       "28               5.3.25 Montenegro V BSC Exhibits.pdf   \n",
       "\n",
       "                                              id  \\\n",
       "0              1wKgBZHiEvQ4aFS61MStso77gKziMHEQd   \n",
       "1              1Cm4AoGbabhpoitAxaRALv9IETTQMaIWs   \n",
       "2              15Rza0jPYg3U-vJWkHVuTPU2OiM0gVmi1   \n",
       "3              1AC2_vPAWxhYRMwq7_uDrmeiqvOlTzkcs   \n",
       "4              13kPU7PKz7xQ2RixdrAUpIv3o6JVcgxKy   \n",
       "5              1PYu3JyrfNJY-ell8lrCCMtKWH0-S0vm-   \n",
       "6              1qPuliKc2bGoVc2ekfb737XRUQANVM3ml   \n",
       "7              1f9tQEDZ8KcnUEdD9JSKSR_Rw4GTXNVW8   \n",
       "8              15iYW8RetZtYhy69KgA2nPFueLm81kAoL   \n",
       "9              1JJruWEteV39YVAEG1qOPyUjqt56en35W   \n",
       "10  1h7HNgoPxc5z5kEFJ9oiLmPP_OQI3L3p5Q4xanmqmJls   \n",
       "11             1kWw7_t6-m5WDoz-c88MFrvtjfZdoF5iB   \n",
       "12             1WlnsDPBLQatCUszGnI4Zt2R3OVd-lFZd   \n",
       "13             1As0L7kpIhLIirWCwaey_weRO2AsUrkxP   \n",
       "14             1rmd-gBa42fwvmtMpf_NpNXXw7uqvj10n   \n",
       "15             1q0Y6cwyd9Kj3N5_KUFzart-nFV8k7Vrk   \n",
       "16             1DMNzQ6S-e6bIqG3SOj8Il4wqO_balBJD   \n",
       "17             1IB_VWepWr2XLgXHofKm1BT1uroApmWeC   \n",
       "18             1ivuhZogU5bTUEinUQxB-NzOogffryzG3   \n",
       "19             1fGfkUtBMMmeNrtIvwHgCsdpQoUqQE43g   \n",
       "20             1eKsx-QeH-pQt0pV_qmg5Ol2CtEMlQK3L   \n",
       "21             1J5jSVTJGsiW8JD0cHPnl7bWmcRL92qYd   \n",
       "22             1YBdqwMyxb-aAvFAcTtSVwrUlvSyi_oEk   \n",
       "23             1PiptUpFauq1Zetx6cOnq8x8mJ8SXqeYi   \n",
       "24             1YsWaPvVbzC65_SVyc-q8XD5fwgfT6ikA   \n",
       "25             18W3Hmj2Zy0Ezzor8Djf3CoRqr2yzXZfa   \n",
       "26             1dB0l97rUEc0DRZ8VaHCN4Jqr8S_zWQyT   \n",
       "27             1DogH_4Tx6MO0IqUuiPYg6NRTfNQw_Gbl   \n",
       "28             1WLNVVWx56IhYmPR-eSlRTBGgY4bsVu0t   \n",
       "\n",
       "                                          webViewLink File Type  \\\n",
       "0   https://drive.google.com/drive/folders/1wKgBZH...    Folder   \n",
       "1   https://drive.google.com/drive/folders/1Cm4AoG...    Folder   \n",
       "2   https://drive.google.com/drive/folders/15Rza0j...    Folder   \n",
       "3   https://drive.google.com/drive/folders/1AC2_vP...    Folder   \n",
       "4   https://drive.google.com/drive/folders/13kPU7P...    Folder   \n",
       "5   https://docs.google.com/spreadsheets/d/1PYu3Jy...     .xlsx   \n",
       "6   https://docs.google.com/spreadsheets/d/1qPuliK...     .xlsx   \n",
       "7   https://drive.google.com/file/d/1f9tQEDZ8KcnUE...      .pdf   \n",
       "8   https://docs.google.com/spreadsheets/d/15iYW8R...     .xlsx   \n",
       "9   https://docs.google.com/spreadsheets/d/1JJruWE...     .xlsx   \n",
       "10  https://docs.google.com/spreadsheets/d/1h7HNgo...     .xlsx   \n",
       "11  https://drive.google.com/file/d/1kWw7_t6-m5WDo...      .pdf   \n",
       "12  https://drive.google.com/file/d/1WlnsDPBLQatCU...      .pdf   \n",
       "13  https://drive.google.com/file/d/1As0L7kpIhLIir...      .pdf   \n",
       "14  https://drive.google.com/file/d/1rmd-gBa42fwvm...      .pdf   \n",
       "15  https://drive.google.com/file/d/1q0Y6cwyd9Kj3N...      .pdf   \n",
       "16  https://drive.google.com/file/d/1DMNzQ6S-e6bIq...      .pdf   \n",
       "17  https://drive.google.com/file/d/1IB_VWepWr2XLg...      .pdf   \n",
       "18  https://drive.google.com/file/d/1ivuhZogU5bTUE...      .pdf   \n",
       "19  https://drive.google.com/file/d/1fGfkUtBMMmeNr...      .pdf   \n",
       "20  https://drive.google.com/file/d/1eKsx-QeH-pQt0...      .pdf   \n",
       "21  https://drive.google.com/file/d/1J5jSVTJGsiW8J...      .pdf   \n",
       "22  https://drive.google.com/file/d/1YBdqwMyxb-aAv...      .pdf   \n",
       "23  https://drive.google.com/file/d/1PiptUpFauq1Ze...      .pdf   \n",
       "24  https://drive.google.com/file/d/1YsWaPvVbzC65_...      .pdf   \n",
       "25  https://drive.google.com/file/d/18W3Hmj2Zy0Ezz...      .pdf   \n",
       "26  https://docs.google.com/spreadsheets/d/1dB0l97...     .xlsx   \n",
       "27  https://docs.google.com/spreadsheets/d/1DogH_4...     .xlsx   \n",
       "28  https://drive.google.com/file/d/1WLNVVWx56IhYm...      .pdf   \n",
       "\n",
       "   date-time processed     MB_size   Folder               path      Locked  \n",
       "0     2025.05.09_00.34    0.000000  Reports  LEGAL/Legal Case/      Folder  \n",
       "1     2025.05.09_00.34    0.000000  Reports  LEGAL/Legal Case/      Folder  \n",
       "2     2025.05.09_00.34    0.000000  Reports  LEGAL/Legal Case/      Folder  \n",
       "3     2025.05.09_00.34    0.000000  Reports  LEGAL/Legal Case/      Folder  \n",
       "4     2025.05.09_00.34    0.000000  Reports  LEGAL/Legal Case/      Folder  \n",
       "5     2025.05.09_00.34    5.448211  Reports  LEGAL/Legal Case/      Locked  \n",
       "6     2025.05.09_00.34    0.091805  Reports  LEGAL/Legal Case/      Locked  \n",
       "7     2025.05.09_00.34    0.214236  Reports  LEGAL/Legal Case/      Locked  \n",
       "8     2025.05.09_00.34   11.295342  Reports  LEGAL/Legal Case/      Locked  \n",
       "9     2025.05.09_00.34   34.597467  Reports  LEGAL/Legal Case/      Locked  \n",
       "10    2025.05.09_00.34    2.337715  Reports  LEGAL/Legal Case/      Locked  \n",
       "11    2025.05.09_00.34    3.735782  Reports  LEGAL/Legal Case/      Locked  \n",
       "12    2025.05.09_00.34    2.482857  Reports  LEGAL/Legal Case/      Locked  \n",
       "13    2025.05.09_00.34    0.189193  Reports  LEGAL/Legal Case/      Locked  \n",
       "14    2025.05.09_00.34    7.999377  Reports  LEGAL/Legal Case/      Locked  \n",
       "15    2025.05.09_00.34    1.393481  Reports  LEGAL/Legal Case/      Locked  \n",
       "16    2025.05.09_00.34    0.042605  Reports  LEGAL/Legal Case/      Locked  \n",
       "17    2025.05.09_00.34    1.203893  Reports  LEGAL/Legal Case/      Locked  \n",
       "18    2025.05.09_00.34    0.056653  Reports  LEGAL/Legal Case/      Locked  \n",
       "19    2025.05.09_00.34   18.390025  Reports  LEGAL/Legal Case/      Locked  \n",
       "20    2025.05.09_00.34   53.414351  Reports  LEGAL/Legal Case/      Locked  \n",
       "21    2025.05.09_00.34    0.232971  Reports  LEGAL/Legal Case/      Locked  \n",
       "22    2025.05.09_00.34    0.228861  Reports  LEGAL/Legal Case/      Locked  \n",
       "23    2025.05.09_00.34    0.228326  Reports  LEGAL/Legal Case/      Locked  \n",
       "24    2025.05.09_00.34    0.118384  Reports  LEGAL/Legal Case/      Locked  \n",
       "25    2025.05.09_00.34  268.867196  Reports  LEGAL/Legal Case/  Not Locked  \n",
       "26    2025.05.09_00.34    5.448211  Reports  LEGAL/Legal Case/  Not Locked  \n",
       "27    2025.05.09_00.34    0.091805  Reports  LEGAL/Legal Case/  Not Locked  \n",
       "28    2025.05.09_00.34  268.726792  Reports  LEGAL/Legal Case/  Not Locked  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PC = 14\n",
    "DriveFolder1(\"'Reports'\",'LEGAL/Legal Case/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8496cdde-43b2-48e9-9e03-1f209dd175ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
